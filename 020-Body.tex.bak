\chapter{Answers to Workbook Questions}

\section{Question One}
 
For each of the distributions below, please provide the requested graphics as well as the numeric results. In both cases, please provide how you realized these (calculations, code, steps…) and why it is the appropriate tools. Do not forget to include the scale of each graphics so a reader can read the numbers represented.\\
a) A vote with outcome for or against follows a Bernoulli distribution where $\textit{P}(vote = "for") = 0.72$. 
Represent the proportion of “for” and “against” in this single Bernoulli trial using a graphics, a 
percentage. Can an expectation be calculated? Justify your answer.\\
b) The number of meteorites falling on an ocean in a given year can be modelled by a Poisson distribution 
with an expectation or $lambda = 77$. Explain why a Poisson distribution is a natural candidate for this 
phenomenon. Give a graphic showing the probability of one, two, three… meteorites falling (until the 
probability is less than 0.5\%). Calculate the median and variance and show them graphically on this 
graphic. \\
c) Let Y be the random variable with the time to hear an owl from your room’s open window (in hours). 
Assume that the probability that you still need to wait to hear the owl after y hours is:
$$0. 70\exp(-0.5 y) + 0. 29\exp(-0.25 y)$$
Find the probability that you need to wait between 2 and 4 hours to hear the owl, compute and display 
the probability density function graph as well as a histogram by the minute. Compute and display in the 
graphics the mean, variance, and quartiles of the waiting times.

\subsection{Answer to Q1(a)} 
$P(vote = "for") = 0.72$, \& $P(vote = "against") = 0.28$ \\ Proportion \parencite[119]{Tilman:RBK} can be calculated in percentage as:

$$\frac{probality of "for"}{total} = \frac{0.72}{1}\% $$
$$Percentage = 72\% $$
and
$$\frac{Probability of "Against"}{total} = \frac{0.28}{1} $$
$$Percentage = 28\% $$

Yes, we can compute an expectation for the Bernoulli distribution. The justification is:
$$ E(X) = \mu = (0)(1 - p) + (1)(p) = p $$
which is the probability distribution.

\begin{figure}[h]
\centering
\includegraphics[width=8cm]{pics/Rplot1a.pdf}
\caption{A barplot illustrating proportion of probability\\ of vote "for and against".}
%\caption{A spiral... smooth vector-based with a clean parametrisation! \\ Nothing to do with \cite{Gage:18}}
\label{fig:spiral}
\end{figure}
\FloatBarrier

\subsection{Answer to Q1(b)} 

The pdf of a poisson distribution is given as:
\begin{equation} P(X = x) =  \frac{\lambda^{x}.e^{\lambda}}{x!} \label{q1b} \end{equation}
Given $\lambda = 77$,  
$$ P(X = x) =  \frac{\lambda^{x}e^{-77}}{x!}$$

From the graph \label{1b}, we determine that x = 58 is the value  for the number of meteorites to yield a probability just less than 0.5%.

The median is given as the solution to the integral expression( \cite[Definition on Section 3.5.2][145]{Richy:AIM} ):
$$ \int_{-\infty}^m f_y (y)dy = 0.5 $$
$$ f_y = \frac{{77^y}e^{-77}}{y!} $$ 

The variance and the mean of a poisson distribution are equal to the parameter: $\lambda \to 77$.
 
We illustrate the plot below:

\begin{figure}[h]
\centering
\includegraphics[width=8cm]{pics/Rplot1b.pdf}
\caption{A plot of pdf for a poisson distribution with lamba =77}
%\caption{A spiral... smooth vector-based with a clean parametrisation! \\ Nothing to do with \cite{Gage:18}}
\label{fig:1b}
\end{figure}
\FloatBarrier

The source code for this plot is shown below(using R):

\begin{verbatim}
 rng=30:100; y=dpois(rng,77)
 plot(y~rng,type="h", ylab ="PDF", 
      xlab = "No. of Meteorites", 
      main="Poisson Distribution with 									  lambda=77") 
 points(y~rng,pch=16,cex=2)
 abline(v=77.0 , col="red")
 abline(v=77.2 , lty=3, col="blue")
 legend("topright", legend = c("median", "Variance"), 
 col = c("red", "blue"), lty = 1) 
\end{verbatim}


\subsection{Answer to Q1(c)}
The probability that you need to wait for 2 to 4 hours is (using 
 \citeurl{Wolfram_Alpha} ):
\begin{equation} P(2 \leq x \leq 4) = \int_2^4 (70e^{-0.5y} + 0. 29e^{-0.25y})dx = 0.712 \label{q1c} \end{equation}

\begin{verbatim}
arr <- seq(2,8,0.1)
dprob <- function(z){
f <- (0.3*exp (-0.5*z) + 0.6* exp (-0.25*z))}
ans <- integrate(dprob, 2, 4); print(ans)
hist(dprob(arr), ylim = c(0,6), xlim = c(0,0.6), prob = TRUE)
print(paste("The quantiles of the system reliability is:",
quantile(dprob(x))))
print(paste("mean of the system reliability is:", mean(dprob(x))))

print(paste("variance of the system reliability is:", var(dprob(x))))
abline(v=mean(dprob(x)), col="red")
abline(v=var(dprob(x)), col="blue")
abline(v=quantile(dprob(x)), col="green")
legend("topright",  \# Add legend to density 
       legend = c("mean", "Variance", "Quantile"), 
       col = c("red", "blue", "green"), 
       lty = 1) 
# Histogram and density
#lines(dprob(arr), col = "red")
box() 

Output:
[1] "The quantiles of the system reliability is: 0.00405638817838003"
[2] "The quantiles of the system reliability is: 0.0142765728246498" 
[3] "The quantiles of the system reliability is: 0.0512723832740649" 
[4] "The quantiles of the system reliability is: 0.196528377703284"  
[5] "The quantiles of the system reliability is: 0.9"                
[1] "mean of the system reliability is: 0.164794304891646"
[1] "variance of the system reliability is: 0.0584640953729553"
\end{verbatim}


\begin{figure}[h]
\centering
\includegraphics[width=8cm]{pics/Rplot1c.pdf}
\caption{A graph of Probability density function for Question 1c.}
\label{fig:1c}
\end{figure}
\FloatBarrier

The graph is shown above with the requested display of mean, variance and quartiles. 

\section{Question Two}
For each of the distributions below, please provide the requested graphics as well as the numeric results. In both cases, please 
provide how you realized these (calculations, code, steps…) and why it is the appropriate tools. Do not forget to include the scale of each graphics so a reader can read the numbers represented.\\
a) Consider that variables X and Y. The realization of a sample of size 20 is given below (where X is the 
first variable and Y is the second):

\begin{table}[!h]
\small
\centering
\begin{tabular}{|l|c|r|}
\hline
X & Y \\
\hline
-1.504 & -235.44\\
0.371 & 166.51\\ 
2.176 & 288.73\\ 
-3.627 & -421.32\\ 
-8.429 & 95.46\\ 
2.759 & 476.25\\ 
3.268 & 4.14\\ 
-9.362 & -366.79\\ 
-2.364 & 92.37\\ 
3.569 & 612.29\\ 
6.969 & -511.51\\ 
-0.466 & 268.67\\ 
4.102 & -350.29\\ 
-8.282 & 234.35\\ 
0.509 & 185.54\\ 
-0.442 & -217.03\\ 
-3.841 & -107.11\\ 
7.938 & 367.32\\ 
-1.062 & -1019.37\\ 
-3.655 & -338.54\\
\hline
\end{tabular}
\caption{Table of X \& Y values}
\label{example:table}
\end{table}
% The table is numbered \ref{example:table}.

Sketch an appropriate plot that displays the values of these  points. Calculate the sample covariance as well as the sample's expectations and variances of X and Y.\\
b) Consider that a ball is thrown with a random angle $\theta \in  (0, 360]$ (in degrees) and a random radius $r \in (0,1]$ (in meters) both independent and uniform. Calculate the density of the variable X and Y (the cartesian coordinates of the point at angle $\theta$ and radius r as well as their expectation and variance.

\subsection{Answer to Q2(a)}
We will display the graphic in R using a scatter diagram because the random variables X and Y are suitable for a scatter plot.

% \begin{figure}[h]
% \centering
% \includegraphics[width=8cm]{pics/Rplot2a.pdf}
% \caption{A graph of Probability density function for Question 2b.}
% \label{fig:2b}
% \end{figure}
% \FloatBarrier

The code for the generation of this graphic plot is (Using R):
\begin{verbatim}
x = c(-1.504, 0.371, 2.176, -3.627, -8.429, 2.759, 3.268,
-9.362, -2.364, 3.569, 6.969, -0.466, 4.102, -8.282, 0.509, 
-0.422, -3.841, 7.938, -1.062, -3.655)

y = c(-235.44, 166.51, 288.73, -421.32, 95.46, 476.25,
4.14,-366.79, 92.37, 612.29, -511.51, 268.67, -350.29, 234.35,
185.54, -217.03, -107.11, 367.32, -1019.37, -338.54)

plot(y ~ x )
\end{verbatim}

\begin{figure}[h]
\centering
\includegraphics[width=8cm]{pics/Rplot2a.pdf}
\caption{A graph of Probability density function for Question 2b.}
\label{fig:1c}
\end{figure}
\FloatBarrier

\begin{verbatim}
abc = data.frame(x, y)
summary(abc)
\end{verbatim}

\begin{table}[!h]
\small
\centering
\begin{tabular}{|l|c|r|}
\hline
 X & Y \\
\hline    
 Min.   :-9.3620 &  Min.   :-1019.37  \\
 1st Qu.:-3.6340 &  1st Qu.: -341.48  \\
 Median :-0.4440 &  Median :   48.26  \\
 Mean   :-0.5676 &  Mean   :  -38.79  \\
 3rd Qu.: 2.8862 &  3rd Qu.:  242.93  \\
 Max.   : 7.9380 &  Max.   :  612.29  \\
\hline
\end{tabular}
\caption{Table of summary of X \& Y values}
\label{example:table}
\end{table}

$$var(y) \to 155839.4$$
$$var(x) \to 22.94998$$
$$mean(y) \to -38.7885$$
$$mean(x) \to -0.56765$$


We can calculate the covariance in R \parencite[281]{Tilman:RBK}or by using equation 2.5.2 in \parencite[126]{Hogg:ITM} thus:

\begin{equation}  Cov(X,Y) = E(XY) - {\mu}_x{\mu}_y \label{q2a1} \end{equation}

Therefore,

$$ Cov(X,Y) = 7265.75 - (-22.02) $$
$$ Cov(X,Y) = 7287.77 $$


\subsection{Answer to Q2(b)} 
From equation 2.1.5 in \cite{Hogg:ITM}, the joint \ac{cdf} of the random vector $(\theta, r)$ of space {(0,360),(0,1)}:

\begin{equation} F_{X,Y} = \int_{-\infty}^{x}\int_{-\infty}^{y}f_{X,Y}(x,y)dxdy \label{q2b} \end{equation}

Which yields the joint pdf:

\begin{equation} f_{X,Y} (x,y) = \frac{\partial^2 F_{X,Y}(x,y)}{\partial x \partial y} \label{q2b1} \end{equation}

For uniform, independent random vectors X and Y, we obtain the density $f_{X,Y}(x,y)$ for  $(x \to \theta, y \to r)$ using \parencite[theorem 2.4.3]{Hogg:ITM},
 
$$ f_{X,Y} (x,y) = \frac{1}{(b-a)(d-c)} = \frac{1}{(1-0)(2\pi - 0)} = \frac{1}{2\pi} $$
where $a \le x \le b,$  $c \le y \le d \to 0 \le \theta \le  2\pi rad,$ $0 \le r \le 1.$

The pdf for $\theta$ can be found from:
\begin{equation} f_{Y} = \int_{-\infty}^{\infty}f_{X,Y}(x,y)dy \label{q2b2} \end{equation}
Thus,
\begin{equation} f_{X} = \int_{0}^{2\pi} \frac{1}{2\pi} d{\theta} \end{equation}
$$ f_{X} = \frac{2\pi}{2\pi} = 1 $$
and the pdf for r can be found from:

\begin{equation} f_{Y} = \int_{0}^{1} \frac{1}{2\pi} d{r} \end{equation}
$$ f_{Y} = \frac{1}{2\pi} $$

The expectation of the random variable X is:
\begin{equation} E(X) = \int_{0}^{2\pi}\int_{0}^{1}xf_{X,Y}(x,y)dxdy \label{q2b3} \end{equation}
\begin{equation} E(X) = \int_{0}^{2\pi}\int_{0}^{1}r(\frac{1}{2\pi})dxdy \end{equation}
\begin{equation} E(X) = \frac{1}{2\pi} \int_{0}^{2\pi}\int_{0}^{1}rd{\theta}dr \end{equation}
Thus,
$$ E(X) = \frac{1}{2\pi}\int_{0}^{2\pi}[\frac{r^2}{2}]_0^1 d{\theta} $$
$$ E(X) = \frac{1}{4\pi}\int_{0}^{2\pi} d{\theta} $$
$$ E(X) = \frac{1}{4\pi} [{\theta}]_0^{2\pi} $$
$$ E(X) = \frac{1}{2} $$

Similarly, 
$$ E(Y) = \int_{0}^{2\pi}\int_{0}^{1}yf_{X,Y}(x,y)dxdy  $$
$$ E(Y) = \int_{0}^{2\pi}\int_{0}^{1} \theta \frac{1}{2\pi} drd{\theta} $$
$E(X) = \pi$ or 360 

We can then calculate the variance for X and Y by using the mathematical expression,

\begin{equation}  {\sigma_x}^2 = E(X^2) - {\mu_x}^2 \to  \int_{0}^{2\pi}\int_{0}^{1} y^2 f_{X,Y}(x,y)dxdy - {\frac{1}{2}}^2 \label{q2b5} \end{equation}

Noting that,
$$ E(X) = \mu_x  $$ and $$ E(Y) = \mu_y $$

$$  {\sigma_x}^2 =  \int_{0}^{2\pi}\int_{0}^{1} r^2 \frac{1}{2\pi} drd{\theta} - {\frac{1}{2}}^2  $$
$$  {\sigma_x}^2 = \frac{1}{2\pi} \int_{0}^{2\pi} [\frac{r^3}{3}]_0^1  d{\theta} - {\frac{1}{2}}^2 $$
$$  {\sigma_x}^2 = \frac{1}{3}  - {\frac{1}{4}} = \frac{1}{12} $$

Similarly,
\begin{equation}  {\sigma_y}^2 = E(Y^2) - {\mu_y}^2 \to  \int_{0}^{2\pi}\int_{0}^{1} x^2 f_{X,Y}(x,y)dxdy - {\pi^2} \label{q2b6} \end{equation}

$$  {\sigma_y}^2 = \frac{1}{2\pi} \int_{0}^{2\pi}[r]_{0}^{1} {\theta}^2  drd{\theta} - {\pi}^2  $$

$$  {\sigma_y}^2 = \frac{1}{2\pi} \int_{0}^{2\pi}[r]_{0}^{1} {\theta}^2  d{\theta} - {\pi}^2  $$

$$  {\sigma_y}^2 = \frac{1}{2\pi} [\frac{\theta^3}{3}]_{0}^{2\pi} - {\pi}^2  $$
$$  {\sigma_y}^2 = \frac{4\pi^2}{3} - {\pi}^2  $$
$$  {\sigma_y}^2 = \frac{\pi^2}{3}  $$

where $\pi rad = 360 deg$

\section{Question Three}
A type of network router has a bandwidth total to first hardware failure called \textit{S} expressed in terabytes. The random variable \textit{S} is modelled by an exponential distribution whose density is given by: $$s(t) = \frac{1}{\theta}e^{-\frac{t}{\theta}}$$
with a single parameter $\theta$. Consider the bandwidth total to failure \textit{T} of the sequence of the two routers of the same type 
(one being brought up automatically when the first is broken).
Express \textit{T} in terms of the bandwidth total to failure of single routers \textit{S1} and \textit{S2}. Formulate realistic assumptions about these 
random variables. Calculate the density function of the variable \textit{T}. 
Given an experiment with the dual router system yielding a sample \textit{$T1, T2, T3, \ldots$}, calculate the likelihood function for \textit{$\theta$}.
Propose a transformation of this likelihood function whose maximum is the same and can be computed easily.
An actual experiment is performed, the infrastructure team has obtained the following bandwidth total to failures:\\
$$31, 157, 156, 64, 243$$
Estimate the model-parameter with the maximum likelihood and compute the expectation of the bandwidth total to failure 
of the dual router system.

\subsection{Answer to Q3}

\cite[From theorem 3.8.3]{Hogg:ITM} gives the combined pdf of a sum of random variables X and Y with pdf's $f_x$ and $f_y$ as: 
\begin{equation} f_w(w) = \int_{-\infty}^{\infty}f_x(x)f_y(w-x)dx \label{q3a1}\end{equation}
Since the router's are $S_1$ and $S_2$, we can sum them up thus: 
\begin{equation} T = S_1 + S_2 \label{q3a2} \end{equation}
So, $X = S_1(t) = \frac{1}{\theta}e^{-\frac{x}{\theta}}$ and $ Y = S_2(t) = \frac{1}{\theta}e^{-\frac{y}{\theta}}$\\
Hence,$$f_t = f_t(w) = \int_{-\infty}^{\infty}(\frac{1}{\theta}e^{-\frac{x}{\theta}}.\frac{1}{\theta}e^{-\frac{y}{\theta}})dx$$
$$f_t = f_t(w) = \int_{-\infty}^{\infty}(\frac{1}{\theta}e^{-\frac{x}{\theta}}.\frac{1}{\theta}e^{-\frac{t-x}{\theta}})dx
$$
$$ f_t(w) = {(\frac{1}{\theta}^2{e^{-t/\theta}}}\int_{-\infty}^{\infty}e^\frac{x}{\theta}e^{-\frac{x}{\theta}})dx$$
$$ f_t(w) = {\frac{1}{\theta}^2{e^{-t/\theta}}}\int_{-t}^{t}dx$$    for $-t \le x \le t$
$$f_t(t) = {\frac{1}{\theta}^2{e^{-t/\theta}}}[x]_{-t}^t$$
\begin{equation} f_t(t) = {\frac{1}{{\theta}^2}{e^{-t/\theta}}}[2t] \label{q3a3} \end{equation}
which is the density function of the variable $t$.  
\\
By comparing the above expression with the exponential distribution, we conclude that they are similar \parencite[3.3.5]{Hogg:ITM} . Hence, we propose that this density function is the exponential distribution. Therefore, by substituting $\lambda = \frac{t}{\theta}$, we obtain the expression for the exponential distribution thus, $$f_t(t) = { {\frac{2}{\theta}}{\lambda}{e^{-\lambda}}}$$
The likelihood function for $\theta$ is given as:
$$L(\theta) = \prod_{i=1}^n{f_t(t)} = \prod_{i=1}^n({\frac{2t}{\theta^2}{e^{-t/\theta}}})$$
$$L(\theta) = ({\frac{(2t)^{\Sigma_i^n{k_i}}}{\theta^{2\Sigma_i^n{k_i}}}{e^{-tn/\theta}}})$$
By employing maximum likelihood estimation which results in application of logarithm and differentiation respectively, we obtain:

First we apply logarithm,
$$\ln(L(\theta)) = -2 \Sigma {k_i}.\ln(\theta)+ \Sigma k_i\ln(2t) -\frac{tn}{\theta}  $$

Then we apply differentiation,
$$ \frac{-2 \Sigma k}{\theta} = \frac{-2tn}{\theta^2} $$

$$ \theta = tn/(\Sigma k) $$

By substituting $\Sigma K = 31 + 157 + 156 + 64 + 243 = 651$ and $t = 2 $ ( for the routers) and $ n = 5$ into the relationship, we obtain:
$$ \theta = \frac{2*5}{651}  =  0.015$$

To calculate the expectation of the bandwidth total to failure of the dual router system, we use:
$$ Expectation = E(S_1 + S_2) = \frac{\Sigma k}{n} = \frac{651}{5} = 130.2 $$

\section{Question Four}

Over a long period of time, the production of 1000 high-quality hammers in a factory seems to have reached a weight with 
an average of 971\textit{g} and standard deviation of 97.6\textit{g}. Propose a model for the weight of the hammers including a probability 
distribution for the weight. What are the assumptions for this model to hold? What parameters does this model have?
A new production system is configured, and one wants to evaluate if the new system makes more constant weights. For this 
a random sample of newly produced hammers is evaluated yielding the following weights:
$$925, 887, 888, 881, 915, 901, 924, 925, 880, 917$$
What hypothesis can you formulate and what test and decision rule can you make to estimate if the new system produces a 
more constant weight? Express these assertions as logical statements involving critical values. What error probabilities can 
you suggest and why? Calculate the $p-value$. Perform the test and express conclusions.

\subsection{Answer to Q4}
We are given the sample size $n = 1000$, mean $\mu = 971g$, and standard deviation as $\sigma = 97.6g$. The model we propose is a normal distribution, 
\begin{equation} P(X=x) \sim N(\mu, \sigma^2) \label{q4a1}\end{equation} 
for the random variable of the weight of the hammer. The assumptions are:
\begin{enumerate}
\item 
the sample size should be large $n \approx 1000$
\item 
X has a $N(\mu, \sigma^2)$ distribution if and only if $Z = {X - \mu}/\sigma$ has a N(0, 1) distribution.\parencite[Section 3.4.8][188]{Hogg:ITM}
\end{enumerate}

The model has parameters $\mu$ and $\sigma^2$ which are the mean and the variance. 
For the new production system, we can formulate the following hypothesis:
\begin{enumerate}
\item
To test $H_0:\mu = \mu_0$ versus $H1:\mu > \mu_0$ at the $\alpha$ level of significance, reject $H_0$ if $z \geq z_\alpha$.
\item
To test $H_0:\mu = \mu_0$ versus $H_1:\mu \geq \mu_0$ at the $\alpha$ level of significance, reject $H_0$ if
$z \geq -z_{\alpha}$.
\item
To test $H_0:\mu = \mu_0$ versus $H_1: \mu = \mu_0$ at the $\alpha$ level of significance, reject $H_0$ if z
is either (1) $\geq$ $-z_{\alpha}/2 $ or (2) $\geq z_{\alpha}/2 $.
\end{enumerate} 
In other words, the null hypothesis, $H_0: \mu_0 = 971g \to$ the new system \textit{does not} make enough weights. In other words, we would reject it if $\mu = 971g$.
The \textit{alternative} hypothesis, $H_1: \mu_0 > 971g \to$ the new production outfit \textit{is effective} in making more weights. So we \textit{dont reject} it if $\mu > 971g$. ( \cite[from][350]{Richy:AIM})\\
Our decision rule: $\bar{y}\le \bar{y^*}\le \mu_0$ $\to$ $904.3 \le \bar{y^*}\le 971$ i.e we want to chose $\bar{y^*}$ such that : $$P(Reject H_0|H_0 is true) = 0.05$$
The mean value, $\bar{y} = 904.3$ from the distribution:
$$\bar{y} = \frac{925+887+888+881+915+901+924+925+880+917}{10} = 904.3$$
Therefore, $$P(\frac{\bar{y} - 971}{97.6/\sqrt{10}} \geq \frac{\bar{y^*}-971}{97.6/\sqrt{10}}) = P(Z\leq -1.64) = 0.05$$ 
From N(Z) table in (Larsen, C), $$P(Z\leq -1.64) = 0.05$$
$$\frac{\bar{y^*}-971}{97.6/\sqrt{10}} = -1.64 \to \bar{y^*} = 920.4$$
This is clearly a case of rejecting our hypothesis. The error probability suggested in this analysis is 5\%. \\
to calculate the \textit{p-value}, we apply the formula:
$$p-value = P(Z\geq\frac{904.3-971}{97.6/\sqrt{10}}) + P(Z\leq\frac{904.3-971}{97.6/\sqrt{10}}) = 0.2483 + 0.2483$$ $$=0.4966$$

\section{Question Five}
(following Larsen \& Marx, exercise 5.6.5)\\
Let $X_1, X_2, \ldots, X_n$ be the random sample of a positive random variable \textit{X} having the density function:
$$ f_x(x;\theta) = \frac{1}{19!{\theta}^{20}}x^{19}e^{\frac{-x}{\theta}}$$
With one parameter $\theta\in\mathbb{R+}$. Find an estimator for $\theta$ that is sufficient.

\subsection{Answer to Q5}
Here, we have a random distribution that is modelled to a poisson distribution pdf. in order to find an estimator for $\theta$ that is sufficient, we apply the maximum likelihood estimation method, MLE(\cite[Eq4.3][104]{Liu:PAB}, \cite[Example 5.2.2][283]{Richy:AIM}). 
\begin{equation} L(\theta) = \prod_{i=1}^n f_x(x; \theta) \label{q5a1} \end{equation}
To show that an estimator $\theta$ exists for $\theta$ such that $X_1, X_2, \ldots, X_n = k_n$ given that $\hat{p} = p_e$ i.e. $$P(X_1=K_1,\ldots,K_n | \hat{p}=p_e) = \frac{P(X_1=k_1,\ldots, X_n=K_n\bigcap\hat{p}=p_e)}{P(\hat{p}=p_e)} = b(K_1,\ldots, K_n)$$
\begin{equation} \frac{\prod_{i=1}^n P_x(K_i; \theta)}{p_e(\theta^i; \theta)}=b(K_1,\ldots, K_n) \label{q5a2} \end{equation}

First, we show that this is a poisson distribution. Let $\lambda = \frac{x}{\theta}$, therefore:
$$f_x(x;\theta) = \frac{\lambda^{19}e^-\lambda}{19!\theta}$$
which is obtained from,$$f_x(x;\theta) = \frac{y^{(r-1)}e^{-y/\theta}}{{r-1}!\theta^r}$$  
Now we proceed with the solution for the estimator.
$$ L(\frac{x}{\theta}) = \frac{1}{\theta}^{\Sigma_i^n K_i}{\prod}_i^n {\frac{\frac{x}{\theta}^{19}.e^{\frac{-x}{\theta}}}{19!}}$$
$$= \frac{1}{{\theta}^{\Sigma_i^{nK_i}}}\frac{e^{-{nx}/\theta}.{\frac{x}{\theta}}^{\Sigma_i^n{K_i}}{\Sigma_i^n{K_i!}}}{{\prod{19K!}.{\Sigma_i^n{19!K_i}}}}$$

\begin{equation} = \frac{1}{{\theta}^{\Sigma_i^{nK_i}}}\frac{e^{-{nx}/\theta}.{nx}^{\Sigma_i^n{K_i}}}{{\Sigma_i^n{19!K_i}}}\frac{\Sigma_i^n{19K_i!}}{\prod19K_i!n^{\Sigma_i^n{19K_i}}} \label{q5a3} \end{equation}

$$= P_\lambda(\lambda_e; \lambda).b(K_i,\ldots,K_n)$$
which is sufficient for $\theta$
\section{Question Six}
(following Hogg, McKean \& Craig, exercise 11.2.2)\\ 
Let $X_1, X_2, \ldots, X_{10}$ be a random sample from a gamma distribution with $\alpha = 3$ and $\beta = 1/{\theta}$. Suppose we believe that $\theta$
follows a gamma-distribution with $\alpha = 3$ and $\beta = 2$:\\
a) Find the posterior distribution of $\theta$.\\
b) If the observed $\overline{x} = 17.1$, what is the Bayes point estimate associated with the square-error loss function?\\
c) What is the Bayes point estimate using the mode of the posterior distribution?\\

\subsection{Answer to Q6}
Let $X_1, X_2,\ldots,X_{10}$ with $n=10$ be a random distribution of gamma model with $\alpha=3$, $\beta=\frac{1}{\theta}$, then:

\begin{equation}  Posterior \to P(\beta|\alpha,\beta,x) \propto P(\beta|\alpha_0,\beta_0)f(x|\alpha,\beta) \label{q6a1} \end{equation}

i.e. Posterior $\propto$ prior $\times$ likelihood, where prior $\sim \Gamma(\alpha_0=3, \beta_0= 2)$. But
\begin{equation} \Gamma(\alpha,\beta)= \frac{\beta^\alpha\theta^{\alpha-1}}{\Gamma(\alpha)}e^{{-\beta}{\theta}} \label{q6a2} \end{equation}


\cite[114]{Liu:PAB} and the likelihood function is obtained from the gamma function as well with $\alpha=3$, $\beta = 2 = \frac{1}{\theta}$. In this analysis, the likelihood function is given as: 
\begin{equation} f(x|\alpha, \beta) = \frac{\beta^\alpha x^{\alpha-1}}{\Gamma(\alpha)}e^{{-\beta}x} \propto  {\beta^\alpha}e^{{-\beta}x} \label{q6a3}\end{equation}
and the prior is of a congugate type which is also a gamma distribution thus:
\begin{equation} Prior \to \Gamma(\alpha_0,\beta_0)= P(\beta|\alpha_0,\beta_0) \propto \frac{\beta_0^\alpha\beta^{\alpha-1}}{\Gamma(\alpha)}e^{{-\beta_0}{\beta}} \propto \beta_0^{\alpha-1}e^{{-\beta_0}{\beta}} \label{q6a4} \end{equation}
And the posterior distribution is also a gamma distribution as shown:$$Posterior \to P(\beta|\alpha_0,\beta_0,x) \propto P(\beta|\alpha_0,\beta_0)f(x|\alpha,\beta) \propto \beta_0^{\alpha-1}e^{{-\beta_0}{\beta}}\beta^{\alpha}e^{{-\beta}{x}}$$
$$ = \beta^{\alpha_0 + {\alpha-1}}e^{{-\beta}({\beta_0 + x})} \propto Gamma(\alpha_0 + \alpha, \beta_0 + x)$$
By substituting $\beta=\frac{1}{\theta}$ for x, we obtain the posterior distribution for $\theta$ thus:
\begin{equation} Posterior \propto \beta^{\alpha_0 + {\alpha-1}}e^{{-\beta}({\beta_0 + \frac{1}{\theta}})} \propto Gamma(\alpha_0 + \alpha, \beta_0 + \frac{1}{\theta}) \label{q6a5}\end{equation}
b) If the observed mean is 17.2, to get the value of theta using the mean of the posterior:
\begin{equation} \bar{x} = \frac{\alpha_0 + \alpha}{\beta + \frac{1}{\theta}} \label{q6a6}\end{equation}
Therefore, $17.2 = \frac{3+3}{2+\frac{1}{\theta}} \Rightarrow \theta = 1.15$ \\
c) The point estimate using the mode of the posterior distribution is obtained from:
\begin{equation} Point estimate = \frac{\alpha - 1}{\beta} \label{q6a7}\end{equation} 

$$ Point estimate, \theta = \frac{6-1}{2.87} = 1.74.$$


